{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "J020_Learning_nim.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hjj31/AI/blob/master/CS50/Learning/J020_Learning_nim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlNHSp2e8v1u"
      },
      "source": [
        "import math\n",
        "import random\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ayC9OPG8v10"
      },
      "source": [
        "class Nim():\n",
        "\n",
        "    def __init__(self, initial=[1, 3, 5, 7]):\n",
        "        self.piles = initial.copy()\n",
        "        self.player = 0\n",
        "        self.winner = None\n",
        "\n",
        "    @classmethod\n",
        "    def available_actions(cls, piles):\n",
        "        actions = set()\n",
        "        for i, pile in enumerate(piles):\n",
        "            for j in range(1, pile + 1):\n",
        "                actions.add((i, j))\n",
        "        return actions\n",
        "\n",
        "    @classmethod\n",
        "    def other_player(cls, player):\n",
        "        return 0 if player == 1 else 1\n",
        "\n",
        "    def switch_player(self):\n",
        "        self.player = Nim.other_player(self.player)\n",
        "\n",
        "    def move(self, action):\n",
        "        pile, count = action\n",
        "\n",
        "        # Check for errors\n",
        "        if self.winner is not None:\n",
        "            raise Exception(\"Game already won\")\n",
        "        elif pile < 0 or pile >= len(self.piles):\n",
        "            raise Exception(\"Invalid pile\")\n",
        "        elif count < 1 or count > self.piles[pile]:\n",
        "            raise Exception(\"Invalid number of objects\")\n",
        "\n",
        "        # Update pile\n",
        "        self.piles[pile] -= count\n",
        "        self.switch_player()\n",
        "\n",
        "        # Check for a winner\n",
        "        if all(pile == 0 for pile in self.piles):\n",
        "            self.winner = self.player"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB2ncLkn8v15"
      },
      "source": [
        "def train(n):\n",
        "    player = NimAI()\n",
        "\n",
        "    # Play n games\n",
        "    for i in range(n):\n",
        "        print(f\"Playing training game {i + 1}\")\n",
        "        game = Nim()\n",
        "\n",
        "        # Keep track of last move made by either player\n",
        "        last = {\n",
        "            0: {\"state\": None, \"action\": None},\n",
        "            1: {\"state\": None, \"action\": None}\n",
        "        }\n",
        "\n",
        "        # Game loop\n",
        "        while True:\n",
        "\n",
        "            # Keep track of current state and action\n",
        "            state = game.piles.copy()\n",
        "            action = player.choose_action(game.piles)\n",
        "\n",
        "            # Keep track of last state and action\n",
        "            last[game.player][\"state\"] = state\n",
        "            last[game.player][\"action\"] = action\n",
        "\n",
        "            # Make move\n",
        "            game.move(action)\n",
        "            new_state = game.piles.copy()\n",
        "\n",
        "            # When game is over, update Q values with rewards\n",
        "            if game.winner is not None:\n",
        "                player.update(state, action, new_state, -1)\n",
        "                player.update(\n",
        "                    last[game.player][\"state\"],\n",
        "                    last[game.player][\"action\"],\n",
        "                    new_state,\n",
        "                    1\n",
        "                )\n",
        "                break\n",
        "\n",
        "            # If game is continuing, no rewards yet\n",
        "            elif last[game.player][\"state\"] is not None:\n",
        "                player.update(\n",
        "                    last[game.player][\"state\"],\n",
        "                    last[game.player][\"action\"],\n",
        "                    new_state,\n",
        "                    0\n",
        "                )\n",
        "\n",
        "    print(\"Done training\")\n",
        "\n",
        "    # Return the trained AI\n",
        "    return player"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcEiOYq58v19"
      },
      "source": [
        "def play(ai, human_player=None):\n",
        "    # If no player order set, choose human's order randomly\n",
        "    if human_player is None:\n",
        "        human_player = random.randint(0, 1)\n",
        "\n",
        "    # Create new game\n",
        "    game = Nim()\n",
        "\n",
        "    # Game loop\n",
        "    while True:\n",
        "\n",
        "        # Print contents of piles\n",
        "        print()\n",
        "        print(\"Piles:\")\n",
        "        for i, pile in enumerate(game.piles):\n",
        "            print(f\"Pile {i}: {pile}\")\n",
        "        print()\n",
        "\n",
        "        # Compute available actions\n",
        "        available_actions = Nim.available_actions(game.piles)\n",
        "        time.sleep(1)\n",
        "\n",
        "        # Let human make a move\n",
        "        if game.player == human_player:\n",
        "            print(\"Your Turn\")\n",
        "            while True:\n",
        "                pile = int(input(\"Choose Pile: \"))\n",
        "                count = int(input(\"Choose Count: \"))\n",
        "                if (pile, count) in available_actions:\n",
        "                    break\n",
        "                print(\"Invalid move, try again.\")\n",
        "\n",
        "        # Have AI make a move\n",
        "        else:\n",
        "            print(\"AI's Turn\")\n",
        "            pile, count = ai.choose_action(game.piles, epsilon=False)\n",
        "            print(f\"AI chose to take {count} from pile {pile}.\")\n",
        "\n",
        "        # Make move\n",
        "        game.move((pile, count))\n",
        "\n",
        "        # Check for winner\n",
        "        if game.winner is not None:\n",
        "            print()\n",
        "            print(\"GAME OVER\")\n",
        "            winner = \"Human\" if game.winner == human_player else \"AI\"\n",
        "            print(f\"Winner is {winner}\")\n",
        "            return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-VLkNuD8v2A"
      },
      "source": [
        "class NimAI():\n",
        "\n",
        "    def __init__(self, alpha=0.5, epsilon=0.1):\n",
        "        self.q = dict()\n",
        "        self.alpha = alpha\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def update(self, old_state, action, new_state, reward):\n",
        "        old = self.get_q_value(old_state, action)\n",
        "        best_future = self.best_future_reward(new_state)\n",
        "        self.update_q_value(old_state, action, old, reward, best_future)\n",
        "\n",
        "    def get_q_value(self, state, action):\n",
        "        if (tuple(state), action) not in self.q:\n",
        "            return 0\n",
        "        \n",
        "        return self.q[tuple(state), action]\n",
        "\n",
        "    def update_q_value(self, state, action, old_q, reward, future_rewards):\n",
        "        self.q[tuple(state), action] = old_q + self.alpha * (reward + future_rewards - old_q)\n",
        "\n",
        "    def best_future_reward(self, state):\n",
        "        best_reward = 0\n",
        "\n",
        "        for available_action in Nim.available_actions(state):\n",
        "            if self.get_q_value(state, available_action) > best_reward:\n",
        "                best_reward = self.get_q_value(state, available_action)\n",
        "\n",
        "        return best_reward\n",
        "\n",
        "    def choose_action(self, state, epsilon=True):\n",
        "        available_actions = Nim.available_actions(state)\n",
        "\n",
        "        # Choose random available action\n",
        "        if epsilon and random.random() <= self.epsilon:\n",
        "            return random.sample(available_actions, 1)[0]\n",
        "        \n",
        "        # Otherwise choose best available action\n",
        "        best_reward = -math.inf\n",
        "\n",
        "        for available_action in available_actions:\n",
        "            if self.get_q_value(state, available_action) > best_reward:\n",
        "                best_reward = self.get_q_value(state, available_action)\n",
        "                best_action = available_action\n",
        "\n",
        "        return best_action"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv8QD0hg8v2E"
      },
      "source": [
        "ai = train(10000)\n",
        "play(ai)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}